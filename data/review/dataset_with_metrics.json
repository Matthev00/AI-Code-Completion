[
    {
        "example_id": 0,
        "prefix": "def create_effnetb2(num_of_class",
        "middle": "es: int, device=\"cuda\"):\n\n    model_weights = to",
        "suffix": "rchvision.models.EfficientNet_B2_Weights.DEFAULT\n    transforms = model_weights.transforms()\n    model = torchvision.models.efficientnet_b2(weights=mo",
        "output": "s, num_of_layers, num_of_classes_per_layer, num_of_classes_per_layer_per_class, num_of_classes_per_layer_per_class_per_class,",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 0.0,
        "chrf": 0.02811143530239163,
        "edit_distance": 109.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 1,
        "prefix": "def create_effnetb2(num_of_classes: int, device=\"cuda\"):\n\n    model_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n    transforms =",
        "middle": " model_weights.transforms()\n    model = torchvision.models.efficientnet_b2(weights=model_w",
        "suffix": "eights).to(device) # noqa 5501\n\n    for param in model.features.parameters():\n        param.requires_grad = False\n\n    utils.set_seeds(42)\n\n    # # Se",
        "output": " torchvision.transforms.Compose([\n        torchvision.transforms.Resize(224),\n        torchvision.transforms.CenterCrop(224),\n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize([0.485,",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 0.0,
        "chrf": 0.15124458838084856,
        "edit_distance": 166.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 2,
        "prefix": "def create_resnet50(num_of_classes: int, device=\"cuda\"):\n\n    model_weights = torchvision.m",
        "middle": "odels.ResNet50_Weights.DEFAULT\n    transforms = model_weights.transforms()\n  ",
        "suffix": "  model = torchvision.models.resnet50(weights=model_weights).to(device)\n\n    # # Freeze layers\n    layers = [model.layer1, model.layer2,\n             ",
        "output": "odels.resnet50(pretrained=True).to(device)\n\n    # Freeze layers\n    layers = [model.layer1, model.layer2,\n              model.layer3, model.layer4,\n              model.layer5",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 1.0003688322288243e-231,
        "chrf": 0.11240763611195419,
        "edit_distance": 133.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 3,
        "prefix": "def create_resnet50(num_of_classes: int, device=\"cuda\"):\n\n    model_weights = torchvision.models.ResNet50_Weights.DEFAULT\n    transforms = model_weights.transforms()\n    model = torchvision.models.resnet50(weights=model_weights).to(device)\n\n    # # Freeze layers\n    layers = [model.layer1, model.la",
        "middle": "yer2,\n              model.layer3, model.layer4",
        "suffix": "]\n    for layer in layers:\n        layer.requires_grad_(False)\n    model.conv1.requires_grad_(False)\n\n    utils.set_seeds(42)\n\n    # # Set cllasifier ",
        "output": "yer2, model.layer3, model.layer4]\n    for layer in layers:\n        layer.requires_grad_(False)\n    model.fc.requires_grad_(False)\n\n    utils.set_seeds(42)\n\n   ",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 5.7592918561109494e-155,
        "chrf": 0.2451414489376745,
        "edit_distance": 125.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 4,
        "prefix": "def create_effnetb0(out_features,\n                    device):\n    effnetb0_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n    transforms = effnetb0_weights.transforms()\n    model = torchvision.models.efficientnet_b0(weights=effnetb0_weights).to(device) # noqa 5501\n\n    for param in model.features.parameter",
        "middle": "s():\n        param.requires_grad = False\n\n",
        "suffix": "    utils.set_seeds(42)\n\n    # # Set cllasifier to suit problem\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.2, inplace=True),\n       ",
        "output": "s():\n        param.requires_grad = False\n\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.2, inplace=True),\n        nn.Linear(in_features=out_features, out_features",
        "model": "starcoder",
        "rating": "correct",
        "bleu": 0.23462350320528,
        "chrf": 0.21253261830824388,
        "edit_distance": 135.0,
        "exact match": 0.0,
        "Manual Rating": 2.0
    },
    {
        "example_id": 5,
        "prefix": "def create_effnetb0(out_features,\n  ",
        "middle": "                  device):\n    effnetb0_weights = torchvision.models.EfficientNet_B0_Weights.DEFAULT\n    transforms = effnetb0_w",
        "suffix": "eights.transforms()\n    model = torchvision.models.efficientnet_b0(weights=effnetb0_weights).to(device) # noqa 5501\n\n    for param in model.features.p",
        "output": "                      effnetb0_weights, device):\n    effnetb0_weights = effnetb0_w",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 5.474895245957125e-78,
        "chrf": 0.6800197306240564,
        "edit_distance": 61.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 6,
        "prefix": "def save_model(model: torch.nn.Module,\n    ",
        "middle": "           target_dir: str,",
        "suffix": "\n               model_name: str):\n    target_dir_path = Path(target_dir)\n    target_dir_path.mkdir(parents=True, exist_ok=True)\n\n    model_save_path =",
        "output": "    target_dir: str,",
        "model": "starcoder",
        "rating": "correct",
        "bleu": 1.491668146240062e-154,
        "chrf": 1.0,
        "edit_distance": 7.0,
        "exact match": 0.0,
        "Manual Rating": 2.0
    },
    {
        "example_id": 7,
        "prefix": "def save_model(model: torch.nn.Module,\n          ",
        "middle": "     target_dir: str,\n               model_name: str):\n    target_dir_path ",
        "suffix": "= Path(target_dir)\n    target_dir_path.mkdir(parents=True, exist_ok=True)\n\n    model_save_path = target_dir_path / model_name\n\n    torch.save(obj=mode",
        "output": "  target_dir: Path,\n            model_name: str):\n    \"\"\"\n    Save the model to a file.\n    \"\"\"\n    obj = {\n       'model_name': model_name,\n       'model_state_dict': model.",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 4.565054879844424e-155,
        "chrf": 0.2579837026181628,
        "edit_distance": 120.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 8,
        "prefix": "def set_seeds(seed: int = 42)",
        "middle": ":\n\n    # Set the seed for general torch operations\n    torch.manual_seed(seed)\n    # Set the seed for CUDA torch operations (ones that happen on the ",
        "suffix": "GPU)\n    torch.cuda.manual_seed(seed)",
        "output": ":\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 2.095023808429367e-234,
        "chrf": 0.4807016225957074,
        "edit_distance": 106.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 9,
        "prefix": "def parse_arguments():\n    \"\"\"\n    Parse arguments:\n    - batch size\n    - hidden units\n    - learning rate as lr\n    - num of epochs\n    \"\"\"\n    parser = argparse.ArgumentParser(description='Script train model TinyVGG')\n    parser.add_argument('--batch_size', type=int, default=32,\n                        ",
        "middle": "help='Batch size for train",
        "suffix": "ing and testing')\n    parser.add_argument('--hidden_units', type=int, default=10,\n                        help='Number of hidden units in the model')\n",
        "output": " help='Batch size')\n    parser.add_argument('--hidden_units', type=int, default=10,\n                        help='Number of hidden units in the model')\n    parser.add_argument('--learning_rate', type=float",
        "model": "starcoder",
        "rating": "correct",
        "bleu": 9.418382295637229e-232,
        "chrf": 0.09997609797044564,
        "edit_distance": 180.0,
        "exact match": 0.0,
        "Manual Rating": 2.0
    },
    {
        "example_id": 10,
        "prefix": "def parse_arguments():\n    \"\"\"\n    Parse arguments:\n    - batch size\n    - hidden units\n    - learning rate as lr\n    - num of epochs\n    \"\"\"\n    parser = argparse.ArgumentParser(description='Script train model TinyVGG')\n    parser.add_argument('--batch_size', type=int, default=32,\n                        help='Batch size for training and testing')\n ",
        "middle": "   parser.add_argument('--hidden_units', type=int, default=10,\n       ",
        "suffix": "                 help='Number of hidden units in the model')\n    parser.add_argument('--lr', type=float, default=0.001,\n                        help='",
        "output": "   parser.add_argument('--hidden_units', type=int, default=1024,\n                        help='Number of hidden units in the model')\n    parser.add_argument('--learning_rate', type=float, default=",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 5.019362538473707e-155,
        "chrf": 0.38077301236655736,
        "edit_distance": 126.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 11,
        "prefix": "def pred_and_store(paths: List[Path],\n                   model: torch.nn.Module,\n                   transform: torchvision.transform",
        "middle": "s,\n                   class_names: List[str],\n                   device=\"cuda\"):\n\n    pred_list = []\n    for path in tqdm(paths",
        "suffix": "):\n        pred_dict = {}\n        pred_dict[\"image_path\"] = path\n        class_name = path.parent.stem\n        pred_dict[\"class_name\"] = class_name\n\n ",
        "output": "):\n        pred_dict = {}\n        pred_dict[\"image_path\"] = path\n        class_name = path.parent.stem\n        pred_dict[\"class_name\"] = class_name\n\n.Compose,\n                   target_transform: torchvision.transform.Compose,\n                   target_target_transform: torchvision.transform.Compose,\n                   target_target_target_transform: torchvision.transform.Compose,\n                   target_target_target_target",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 1.012071042130996e-231,
        "chrf": 0.08855393233590232,
        "edit_distance": 339.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 12,
        "prefix": "def pred_and_store(paths: List[Path],\n                   model: torch.nn.Module,\n                   transform: torchvision.transforms,\n                   class_names: List[str],\n                   device=\"cuda\"):\n\n    pred_list = []\n    for path in tqdm(paths):\n        pred_dict = {}\n        pred_dict[\"image_path\"] = pa",
        "middle": "th\n        class_name = path.parent.stem\n        pred_dict[\"class_name\"] = class_name\n\n        start_time = timer()\n\n        img = Ima",
        "suffix": "ge.open(path)\n\n        transformed_img = transform(img).unsqueeze(0).to(device)\n\n        model.to(device)\n        model.eval()\n\n        with torch.inf",
        "output": "th\n        pred_dict[\"class_name\"] = class_names\n        pred_dict[\"pred\"] = model(transformed_img)\n        pred_list.append(pred_dict)\n\n    return pred_list\n\n\ndef pred_and",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 5.726015560822316e-155,
        "chrf": 0.3311279378807433,
        "edit_distance": 104.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 13,
        "prefix": "def predict(img: Image,",
        "middle": "\n            model: torch.nn.Module,\n            transform: torchvision.transforms,\n       ",
        "suffix": "     class_names: List[str],\n            device=\"cuda\"):\n\n    start_time = timer()\n\n    transformed_img = transform(img).unsqueeze(0).to(device)\n\n    ",
        "output": " img_path: str, model: nn.Module, device=\"cuda\"):\n\n    img = img.to(device)\n\n    with torch.no_grad():\n        output = model(img)\n\n    return output.cpu().numpy()\n\n\n",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 9.257324954728539e-232,
        "chrf": 0.17741799896387156,
        "edit_distance": 127.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 14,
        "prefix": "def predict(img: Image,\n            model: torch.nn.Module,\n            transform: torchvision.transforms,\n            class_names: List[str],\n            device=\"cuda\"):\n\n    start_time = timer()\n\n    transformed_img = transform(img).u",
        "middle": "nsqueeze(0).to(device)\n\n    model.to(device)\n    model.eval(",
        "suffix": ")\n\n    with torch.inference_mode():\n        pred_logit = model(transformed_img)\n        pred_prob = torch.softmax(input=pred_logit, dim=1)\n\n    pred_l",
        "output": "nit_transform(",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 0.09581529581529587,
        "edit_distance": 55.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 15,
        "prefix": "def create_writer(experiment_name: str,\n                  model_name: str,\n                  extra: str = None) -> SummaryWriter:\n    \"\"\"\n    Creates a torch.util",
        "middle": "s.tensorboard.writer.SummaryWriter() instance saving to a specific log_dir. # noqa 5501\n    log_dir is a co",
        "suffix": "mbination of runs/timestamp/experiment_name/model_name/extra. # noqa 5501\n    Where timestamp is the current date in YYYY-MM-DD format.\n\n    Args:\n   ",
        "output": "s.SummaryWriter for the given experiment_name and model_name.\n\n    Args:\n    experiment_name: The name of the experiment.\n    model_name: The name of the model.\n    extra: A string to be appended to the",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 7.919883909890055e-232,
        "chrf": 0.16120375153423042,
        "edit_distance": 157.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 16,
        "prefix": "def create_writer(experiment_name: str,\n                  model_name: str,\n                  extra: str = None) -> SummaryWriter:\n",
        "middle": "    \"\"\"\n    Creates a torch.utils.tensorboard.writer.Summar",
        "suffix": "yWriter() instance saving to a specific log_dir. # noqa 5501\n    log_dir is a combination of runs/timestamp/experiment_name/model_name/extra. # noqa 5",
        "output": "    \"\"\"\n    Creates a summary writer for a given experiment_name and model_name.\n    :param experiment_name: The name of the experiment.\n    :param model_name: The name of the model.\n    :param extra: A",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 1.6143590570897344e-78,
        "chrf": 0.1284254668742045,
        "edit_distance": 160.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 17,
        "prefix": "def plot_loss_curves(results):\n    \"\"\"Plots training curves of a results",
        "middle": " dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"t",
        "suffix": "rain_loss\": [...],\n             \"train_acc\": [...],\n             \"test_loss\": [...],\n             \"test_acc\": [...]}\n    \"\"\"\n    loss = results[\"train",
        "output": "s.\"\"\"\n    fig, ax = plt.subplots(1, 1)\n    ax.plot(results[\"train_loss\"], label=\"train_loss\")\n    ax.plot(results[\"t",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 0.13323186423820116,
        "edit_distance": 95.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 18,
        "prefix": "def plot_loss_curves(results):\n    \"\"\"Plots training curves of a results dictionary.\n\n    Args:\n        results (dict): dictionary containing list of values, e.g.\n            {\"train_loss\": [...],\n             \"tra",
        "middle": "in_acc\": [...],\n             \"test_loss\": [",
        "suffix": "...],\n             \"test_acc\": [...]}\n    \"\"\"\n    loss = results[\"train_loss\"]\n    test_loss = results[\"test_loss\"]\n\n    accuracy = results[\"train_acc",
        "output": "in_acc\": [...],\n             \"test_loss\": [...]}\n    \"\"\"\n    loss = results[\"train_loss\"]\n    test_loss = results[\"test_loss\"]\n\n    accuracy = results[\"train_acc\"]\n    test_acc =",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 2.5106669237851586e-78,
        "chrf": 0.21049180518434138,
        "edit_distance": 135.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 19,
        "prefix": "def pred_and_plot_image(model: nn.Module,\n                        image_path: str,\n                        class_names: List[str],\n                        image_size: Tuple[int, int] = (224, 224),\n                        transform: torchvision.transforms = None,\n                        device: torch.device = \"cuda\"):\n    # Open an image\n    img = Image.open(image_path)\n\n    # Create t",
        "middle": "ransformation\n    if transform:\n        imag",
        "suffix": "e_transform = transform\n    else:\n        image_transform = transforms.Compose([\n            transforms.Resize(image_size),\n            transforms.ToT",
        "output": "he target tensor\n    target = torch.zeros(1, 1, 3, 3).to(device)\n\n    # Get the image size\n    image_size = image_size\n\n    # Get the transform\n    transform = transform if transform",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 8.06798322521923e-232,
        "chrf": 0.13603463657966153,
        "edit_distance": 149.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 20,
        "prefix": "def pred_and_plot_image(model: nn.Module,\n                        image_path: str,\n                        class_names: List[str],\n                        image_size: Tuple[int, int] = (224, 224),\n                        transform: torchvision.transforms = None,\n                        dev",
        "middle": "ice: torch.device = \"cuda\"):\n    # Open an image\n    img = Image.open(image_path)\n\n    # Create transformati",
        "suffix": "on\n    if transform:\n        image_transform = transform\n    else:\n        image_transform = transforms.Compose([\n            transforms.Resize(image_",
        "output": "l_transform: torchvision.transforms = None,\n                        **kwargs):\n    \"\"\"\n    Predict the class of an image using a trained deep learning model.\n\n    Args:\n        model: The trained deep learning model.\n        image_path: The path to",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 3.677591797349584e-155,
        "chrf": 0.19533614417284315,
        "edit_distance": 191.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 21,
        "prefix": "def download_data(data_path: Path,\n                  train_transform: transforms = None,\n                  test_transform: transforms = None):\n\n    train_data = datasets.OxfordIIITPet(root=data_path,\n                                        split=\"trainval",
        "middle": "\",\n                            ",
        "suffix": "            target_types=\"category\",\n                                        transform=train_transform,\n                                        downlo",
        "output": "\",\n                                        transform=train_transform,\n                                        downloaddir=data_path,\n                                        target_types=\"category\",\n                                        transform=test_transform,\n                                        downloaddir=data_path,\n                                        target_types=\"category\",\n                                        transform=",
        "model": "starcoder",
        "rating": "correct",
        "bleu": 1.0832677820940877e-231,
        "chrf": 0.0035876996007340872,
        "edit_distance": 411.0,
        "exact match": 0.0,
        "Manual Rating": 2.0
    },
    {
        "example_id": 22,
        "prefix": "def download_data(data_path: Path,\n                  train_transform: transforms = None,\n                  test_transform: transforms = None):\n\n    train_data = datasets.OxfordIIITPet(root=data_path,\n             ",
        "middle": "                           split=\"trainval\",\n      ",
        "suffix": "                                  target_types=\"category\",\n                                        transform=train_transform,\n                        ",
        "output": "                          train=True,\n  ",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 0.0,
        "chrf": 0.27624064222190187,
        "edit_distance": 17.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 23,
        "prefix": "def split_data(dataset: datasets,\n               split: float = 0.2):\n\n    length1 = int(split ",
        "middle": "* len(dataset))\n    length2 = len(datase",
        "suffix": "t) - length1\n\n    set_seeds(42)\n\n    random_split1, random_split2 = random_split(\n        dataset=dataset,\n        lengths=[length1, length2],\n       ",
        "output": "/ 1)\n    length2 = int(split / 2)\n\n    length1 = length1 - length1\n    length2 = length2 - length2\n\n    length1 = length1 - length1\n    length2 = length2 -",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 3.5131878770278888e-155,
        "chrf": 0.12007037824362617,
        "edit_distance": 127.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 24,
        "prefix": "def split_data(dataset: datasets,\n               split: float = 0.2):\n\n    length1 = int(spli",
        "middle": "t * len(dataset))\n    length2 = len(dataset) - length1\n\n    set_seeds(42)\n\n    random_split1, random_split2 = ra",
        "suffix": "ndom_split(\n        dataset=dataset,\n        lengths=[length1, length2],\n        generator=torch.manual_seed(42))\n\n    return random_split1, random_sp",
        "output": "t(dataset.data.shape[0] * split))\n    length2 = int(split(dataset.data.shape[0] * (1 - split)))\n\n    random_split1 = dataset.data[:length1]",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 6.311514251575017e-155,
        "chrf": 0.37052484829600757,
        "edit_distance": 79.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 25,
        "prefix": "def create_dataloaders(\n    train_dir: str,\n    test_dir: str,\n    transform: transforms.Co",
        "middle": "mpose,\n    batch_size: int,\n    num_workers: int\n):\n    \"\"\"\n    Creat",
        "suffix": "es training and testing DataLoaders.\n\n    Takes in a training directory and testing directory path and turns\n    them into PyTorch Datasets and then i",
        "output": "nform,\n    batch_size: int,\n    num_workers: int,\n) -> Tuple[torch.utils.data.DataLoader, torch.utils.data.DataLoader]:\n    \"\"\"\n    Creates dataloaders for training and testing Data",
        "model": "starcoder",
        "rating": "correct",
        "bleu": 2.570061783884003e-78,
        "chrf": 0.2639107133884319,
        "edit_distance": 116.0,
        "exact match": 0.0,
        "Manual Rating": 2.0
    },
    {
        "example_id": 26,
        "prefix": "def create_dataloaders(\n    train_dir: str,\n    test_dir: str,\n    transform: transforms.Compose,\n    batch_size: int,\n    num_workers: int\n):\n    \"\"\"\n    Creates training and testing DataLoaders.\n\n    Takes in a training directory and testing directory path and turns\n    them into PyTorch Datasets and then into PyTorch DataLoaders.\n\n    Args:\n        train_dir: Path to training directory.\n        test_dir: Path to testing directory.\n        transform: torchvision transforms to perform on training and testing data. # noqa 5501\n        batch_size: Number of samples per batch in each of the DataLoaders.\n        num_workers: An integer for number of workers per DataLoader.\n\n    Returns:\n    ",
        "middle": "    A tuple of (train_dataloade",
        "suffix": "r, test_dataloader, class_names).\n        Where class_names is a list of the target classes.\n    \"\"\"\n\n    # Create datasets using datasets.ImageFolder",
        "output": "    A PyTorch DataLoaders.\n    \"\"\"\n\n    # Create datasets using datasets.ImageFolder\n    train_dataset = datasets.ImageFolder(\n        train_dir, transform=transform, target_transform=transform\n    )\n    test_dataset = datasets",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 8.726094729337945e-232,
        "chrf": 0.07230733766555357,
        "edit_distance": 200.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 27,
        "prefix": "def main():\n\n    ssl._create_default_https_context = ssl._create_unverified_context # noqa 5501\n    transform = transforms.Compose([transforms.ToTensor(),\n             ",
        "middle": "                       transforms.Resize((224, 224))])\n    train_data, test_da",
        "suffix": "ta = download_data(data_path=Path(\"data\"),\n                                          train_transform=transform,\n                                      ",
        "output": "   transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\n    data_path = Path(\"data\")\n    train_data = download",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 0.2606137048687605,
        "edit_distance": 88.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 28,
        "prefix": "def main():\n\n    ssl._create_default_https_context = ssl._create_unverified_context # noqa 5501\n    transform = transforms.Compose([transfo",
        "middle": "rms.ToTensor(),\n                        ",
        "suffix": "            transforms.Resize((224, 224))])\n    train_data, test_data = download_data(data_path=Path(\"data\"),\n                                        ",
        "output": "r.ToTensor(),\n",
        "model": "starcoder",
        "rating": "correct",
        "bleu": 0.0,
        "chrf": 0.8974869445201771,
        "edit_distance": 26.0,
        "exact match": 0.0,
        "Manual Rating": 2.0
    },
    {
        "example_id": 29,
        "prefix": "def train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               device: torch.device = \"cuda\") -> Tuple[float, float]:\n    \"\"\"Trains a model for single epoch\n\n    Args:\n        model (torch.nn.Module): model to be trained\n        dataloader (torch.utils.data.DataLoader): d",
        "middle": "ataloader to be trained on\n        loss_fn (t",
        "suffix": "orch.nn.Module): loss function\n        optimizer (torch.optim.Optimizer): optimizer\n        device (torch.device, optional): torch device. Defaults to",
        "output": "ata loader\n        loss_fn (t \"cuda\"\n\n    Returns:\n        float: loss value",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 6.08970970641905e-155,
        "chrf": 0.34079802996240555,
        "edit_distance": 47.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 30,
        "prefix": "def train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer,\n               device: torch.device = \"cuda\") -> Tuple[float, float]:\n    \"\"\"Trains a model for single epoch\n\n    Args:\n        model (torch.nn.Module): model to be trained\n        dataloader (torch.utils.data.DataLoader): dataloader to be trained on\n        loss_fn (torch.nn.Module): loss function",
        "middle": "\n        optimizer (torch.optim.Optimizer): optimizer\n        device (torch.device, optiona",
        "suffix": "l): torch device. Defaults to \"cuda\".\n\n    Returns:\n        Tuple[flat, float]: training loss and training accuracy metrics.\n        In the form (trai",
        "output": "\n        optimizer (torch.optim.Optimizer): optimizer to be trained\n        device (torch.device): device to be used for training\n\n    Returns:\n        Tuple[flat, float]: training loss and training accuracy metrics.\n        In the form (trai",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 1.7845935722073316e-78,
        "chrf": 0.3480192518105289,
        "edit_distance": 152.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 31,
        "prefix": "def test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device = \"cuda\") -> Tuple",
        "middle": "[float, float]:\n    \"\"\"Tests a model for single epoch\n\n    Args:\n        model (torch.nn.Module): model to be tes",
        "suffix": "ted\n        dataloader (torch.utils.data.DataLoader): dataloader to be tested on\n        loss_fn (torch.nn.Module): loss function\n        device (torc",
        "output": "\n            -> Tuple[torch.Tensor, torch.Tensor]:\n        \"\"\"\n        Test step function\n        \"\"\"\n        model.eval()\n        loss = loss_fn(model(dataloader.dataset.X, dataloader.dataset.y))\n        assert",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 0.20986035698628766,
        "edit_distance": 158.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 32,
        "prefix": "def test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module,\n              device: torch.device = \"cuda\") -> Tuple[float, float]:\n    \"\"\"Tests a model for single epoch\n\n    Args:\n        model (torch.nn.Module): model to be tested\n        dataloader (torch.utils.data.DataLoader): dataloader to be tested on\n   ",
        "middle": "     loss_fn (torch.nn.Module): loss function\n        device (torch.device, optional): torch device. Defaults to \"",
        "suffix": "cuda\".\n\n    Returns:\n        Tuple[flat, float]: testing loss and testing accuracy metrics.\n        In the form (test_loss, test_accuracy). For exampl",
        "output": "     loss_fn (torch.nn.Module): loss function to be tested\n        device (torch.device): device to be tested\n\n    Returns:\n        Tuple[flat, float]: testing loss and testing accuracy metrics.\n        In the form (test",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 0.10008350737965103,
        "chrf": 0.3976047254574058,
        "edit_distance": 124.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 33,
        "prefix": "def train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          writer: SummaryWriter,\n          device=\"cuda\"):\n    \"\"\"\n    Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n        model: A PyTorch model to be trained and tested.\n        train_dataloader: A DataLoader instance for the model to be trained on.\n        test_dataloader: A DataLoader instance for the model to be tested on.\n        optimizer: A PyTorch optimizer to help minimize the loss function.\n        loss_fn: A PyTorch loss function to calculate loss on both datasets.\n        epochs: An integer indicating how many epochs to train for.\n        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n        A dictionary of training and testing loss as well as training and\n        testing accuracy metrics. Each metric has a value in a list for\n        each epoch.\n    \"\"\"\n\n    # Create empty results dictionary\n    results = {\"train_loss\": [],\n               \"train_acc",
        "middle": "\": [],\n               \"test_loss\": [],\n               \"test_acc\": []\n    ",
        "suffix": "           }\n\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                          ",
        "output": "\": [],\n               \"test_loss\": [],\n               \"test_acc\": []}\n\n    # Iterate over the training data\n    for data in train_dataloader:\n        # Compute the loss\n        loss = loss_fn(model(data.to(",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.15415064977510756,
        "chrf": 0.2607489540843873,
        "edit_distance": 133.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 34,
        "prefix": "def train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs: int,\n          writer: SummaryWriter,\n          device=\"cuda\"):\n    \"\"\"\n    Trains and tests a PyTorch model.\n\n    Passes a target PyTorch models through train_step() and test_step()\n    functions for a number of epochs, training and testing the model\n    in the same epoch loop.\n\n    Calculates, prints and stores evaluation metrics throughout.\n\n    Args:\n        model: A PyTorch model to be trained and tested.\n        train_dataloader: A DataLoader instance for the model to be trained on.\n        test_dataloader: A DataLoader instance for the model to be tested on.\n        optimizer: A PyTorch optimizer to help minimize the loss function.\n        loss_fn: A PyTorch loss function to calculate loss on both datasets.\n        epochs: An integer indicating how many epochs to train for.\n        device: A target device to compute on (e.g. \"cuda\" or \"cpu\").\n\n    Returns:\n        A dictionary of training and testing loss as well as training and\n        testing accuracy metrics. Each metric has a value in a list for\n        each epoch.\n    \"\"\"\n\n    # Create empty results dictionary\n    results =",
        "middle": " {\"train_loss\": [],\n               \"train_acc\": [],\n               \"test_loss\": [],\n    ",
        "suffix": "           \"test_acc\": []\n               }\n\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n            ",
        "output": " {\n            \"train_loss\": [],\n            \"train_acc\": []\n        }\n\n    for batch_idx, (data, target) in enumerate(train_dataloader):\n        # Move data to device\n        data, target = data.to(",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 3.918477812555336e-155,
        "chrf": 0.26397485783538355,
        "edit_distance": 127.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 35,
        "prefix": "def main():\n    args = utils.parse_arguments()\n    BATCH_SIZE = args.batch_size\n    EPOCHS = args.num_epochs # noqa 5501\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    NUM_WORKERS = os.cpu_count()\n\n    # # Create models\n    effnetb2, effnetb2_transforms = model_builder.create_effnetb2(\n        num_of_classes=3,\n        device=device)\n    resnet50, resnet50_transforms = model_builder.create_resnet50(\n        num_of_classes=3,\n        device=device)\n\n    # # Create data 3 classes\n    data_path = Path(\"data_3\")\n    train_path = data_path / \"train\"\n    test_path = data_path / \"test\"\n    train_dataloader, test_dataloader, class_names = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=effnetb2_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS)\n\n    # # # Train model\n    # optimizer = torch.optim.Adam(effnetb2.parameters(), lr=1e-2)\n    # loss_fn = nn.CrossEntropyLoss()\n    # result = engine.train(model=effnetb2,\n    #                       train_dataloader=train_dataloader,\n    #                       test_dataloader=test_dataloader,\n    #                       optimizer=optimizer,\n    #                       loss_fn=loss_fn,\n    #                       epochs=EPOCHS,\n    #                       writer=utils.create_writer(experiment_name=\"test\",\n    #                                                  model_name=\"xyz\"),\n    #                       device=device)\n\n    # utils.plot_loss_curves(results=result)\n\n    # # Load best model\n    best_model_path = \"models/Pretrained_resnet50_10_epochs.pth\"\n    resnet50.load_state_dict(torch.load(best_model_path))\n\n    model_size = Path(best_model_path).stat().st_size // (1024*1024)\n    # print(f\"Model size {model_size}\")\n\n    # # # Predict on image\n    # img_to_plot = 8\n    # test_image_path_list = list(Path(test_path).glob(\"*/*.jpg\"))\n    # img_path_sample = random.sample(population=test_image_path_list,\n    #                                 k=img_to_plot)\n    # for img_path in img_path_sample:\n    #     utils.pred_and_plot_image(model=resnet50,\n    #                               image_path=img_path,\n    #                               class_names=class_names,\n    #                               image_size=(288, 288))\n\n    # # Train model on all classes\n\n    # Create data (all classes)\n    # Create a model\n    model, test_transforms = model_builder.create_effnetb2(num_of_classes=37,\n                                                    ",
        "middle": "       device=device)\n    train_transf",
        "suffix": "orms = transforms.Compose([transforms.TrivialAugmentWide(),\n                                           test_transforms])\n\n    train_data, test_data = ",
        "output": "     device=device)\n    test_transf create_dataloaders(\n        train_dir=train_path",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 1.2882297539194154e-231,
        "chrf": 0.34742840754976884,
        "edit_distance": 52.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 36,
        "prefix": "def main():\n    args = utils.parse_arguments()\n    BATCH_SIZE = args.batch_size\n    EPOCHS = args.num_epochs # noqa 5501\n    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n    NUM_WORKERS = os.cpu_count()\n\n    # # Create models\n    effnetb2, effnetb2_transforms = model_builder.create_effnetb2(\n        num_of_classes=3,\n        device=device)\n    resnet50, resnet50_transforms = model_builder.create_resnet50(\n        num_of_classes=3,\n        device=device)\n\n    # # Create data 3 classes\n    data_path = Path(\"data_3\")\n    train_path = data_path / \"train\"\n    test_path = data_path / \"test\"\n    train_dataloader, test_dataloader, class_names = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=effnetb2_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS)\n\n    # # # Train model\n    # optimizer = torch.optim.Adam(effnetb2.parameters(), lr=1e-2)\n    # loss_fn = nn.CrossEntropyLoss()\n    # result = engine.train(model=effnetb2,\n    #                       train_dataloader=train_dataloader,\n    #                       test_dataloader=test_dataloader,\n    #                       optimizer=optimizer,\n    #                       loss_fn=loss_fn,\n    #                       epochs=EPOCHS,\n    #                       writer=utils.create_writer(experiment_name=\"test\",\n    #                                                  model_name=\"xyz\"),\n    #                       device=device)\n\n    # utils.plot_loss_curves(results=result)\n\n    # # Load best model\n    best_model_path = \"models/Pretrained_resnet50_10_epochs.pth\"\n    resnet50.load_state_dict(torch.load(best_model_path))\n\n    model_size = Path(best_model_path).stat().st_size // (1024*1024)\n    # print(f\"Model size {model_size}\")\n\n    # # # Predict on image\n    # img_to_plot = 8\n    # test_image_path_list = list(Path(test_path).glob(\"*/*.jpg\"))\n    # img_path_sample = random.sample(population=test_image_path_list,\n    #                                 k=img_to_plot)\n    # for img_path in img_path_sample:\n    #     utils.pred_and_plot_image(model=resnet50,\n    #                               image_path=img_path,\n    #                           ",
        "middle": "    class_names=class_names,\n    #                             ",
        "suffix": "  image_size=(288, 288))\n\n    # # Train model on all classes\n\n    # Create data (all classes)\n    # Create a model\n    model, test_transforms = model_",
        "output": "                 ",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 1.0000000000000001e-16,
        "edit_distance": 46.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 37,
        "prefix": "    def predict(img: Image):\n\n        start = timer()\n\n      ",
        "middle": "  transformed_img = test_transforms(img).unsqueeze(0).to(device)\n\n        model.to",
        "suffix": "(device)\n        model.eval()\n\n        with torch.inference_mode():\n            pred_logit = model(transformed_img)\n            pred_prob = torch.soft",
        "output": "  transformed_img = img.transform",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 8.121328445417258e-155,
        "chrf": 0.6949668843796344,
        "edit_distance": 53.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 38,
        "prefix": "    def predict(img: Image):\n\n        start = timer()\n\n        transformed_img = test_transforms(img).unsqueeze(0).to",
        "middle": "(device)\n\n        model.to(device)\n        model.eval()\n\n        with torch.inference_mode():\n            pred_logit = model(transformed_i",
        "suffix": "mg)\n            pred_prob = torch.softmax(input=pred_logit,\n                                      dim=1)\n\n        pred_labels_and_probs = {class_names",
        "output": "(device)\n\n        pred_logit = model(transformed_img)\n        pred_prob = torch.softmax(input=pred_logit,\n                                      dim=1)\n\n        end = timer()\n\n        print(f\"Time taken for {",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 5.157006819435075e-155,
        "chrf": 0.37711201945637995,
        "edit_distance": 137.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 39,
        "prefix": "def main():\n    args = utils.parse_arguments()\n    BATCH_SIZE = args.batch_size\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    NUM_WORKERS = os.cpu_count()\n    num_classes = 3\n    mlflow.set_experiment(\"Pet Recognition\")\n\n    # # Create models\n    effnetb2, effnetb2_transforms = create_effnetb2(\n        num_of_classes=num_classes, device=device\n    )\n    resnet50, resnet50_transforms = create_resnet50(\n        num_of_classes=num_classes, device=device\n    )\n    effnetb0, effnetb0_transforms = create_effnetb0(\n        out_features=num_classes, device=device\n    )\n\n    # # Create dataloaders\n    data_path = Path(\"data_3\")\n    train_path = data_path / \"train\"\n    test_path = data_path / \"test\"\n    (\n        train_dataloader_effnetb2,\n        test_dataloader_effnetb2,\n        class_names,\n    ) = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=effnetb2_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n    )\n\n    (\n        train_dataloader_effnetb0,\n        test_dataloader_effnetb0,\n        class_names,\n    ) = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=effnetb0_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n    )\n\n    (\n        train_dataloader_resnet50,\n        test_dataloader_resnet50,\n        class_names,\n    ) = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=resnet50_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n    )\n\n    # # Create experiment\n    epochs = [5, 10]\n    models = [\"resnet50\", \"effnetb0\", \"effnetb2\"]\n    experiment_num = 0\n\n    # # Experiment\n    for epoch in epochs:\n        for model_name in models:\n            experiment_num += 1\n            print(f\"[INFO] Experiment number: {experiment_num}\")\n          ",
        "middle": "  print(f\"[INFO] Model: {model_name}\")\n            print(f\"[INFO] Number of epochs: {epoc",
        "suffix": "h}\")\n\n            # Create model\n            if model_name == \"effnetb2\":\n                model, _ = create_effnetb2(num_of_classes=num_classes, devic",
        "output": "  # Create model\n            if model_name == \"effnetb2\":\n                model, _ = create_effnetb2(num_of_classes=num_classes, devic",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 0.1551133578343901,
        "edit_distance": 94.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 40,
        "prefix": "def main():\n    args = utils.parse_arguments()\n    BATCH_SIZE = args.batch_size\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n    NUM_WORKERS = os.cpu_count()\n    num_classes = 3\n    mlflow.set_experiment(\"Pet Recognition\")\n\n    # # Create models\n    effnetb2, effnetb2_transforms = create_effnetb2(\n        num_of_classes=num_classes, device=device\n    )\n    resnet50, resnet50_transforms = create_resnet50(\n        num_of_classes=num_classes, device=device\n    )\n    effnetb0, effnetb0_transforms = create_effnetb0(\n        out_features=num_classes, device=device\n    )\n\n    # # Create dataloaders\n    data_path = Path(\"data_3\")\n    train_path = data_path / \"train\"\n    test_path = data_path / \"test\"\n    (\n        train_dataloader_effnetb2,\n        test_dataloader_effnetb2,\n        class_names,\n    ) = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=effnetb2_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n    )\n\n    (\n        train_dataloader_effnetb0,\n        test_dataloader_effnetb0,\n        class_names,\n    ) = create_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=effnetb0_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n    )\n\n    (\n        train_dataloader_resnet50,\n        test_dataloader_resnet50,\n        class_names,\n    ) = c",
        "middle": "reate_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,",
        "suffix": "\n        transform=resnet50_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS,\n    )\n\n    # # Create experiment\n    epochs = ",
        "output": "reate_dataloaders(\n        train_dir=train_path,\n        test_dir=test_path,\n        transform=resnet50_transforms,\n        batch_size=BATCH_SIZE,\n        num_workers=NUM_WORKERS",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 5.775353993361614e-78,
        "chrf": 0.45111367940791985,
        "edit_distance": 102.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 41,
        "prefix": "def main():\n    device = torch.device(\"cuda:0\" if torch.cuda.is_available() e",
        "middle": "lse \"cpu\")\n    # # Setup class names\n    with open(\"class_names.txt\", \"r\") as filehandle:\n        class",
        "suffix": "_names = [bread.strip() for bread in filehandle.readlines()]\n\n    # # Create model\n    model, model_transforms = create_effnetb2(\n        num_of_class",
        "output": "lse \"cpu\")\n    model.to(device)\n\n    # # Load model\n    # model = effnetb2.EffNetB2(num_of_class=2, num_of_layers=2, num_of_",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 7.098450576376767e-155,
        "chrf": 0.1676057842317806,
        "edit_distance": 91.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 42,
        "prefix": "def main():\n    device = torch.device(\"cuda:0\" if to",
        "middle": "rch.cuda.is_available() else \"cpu\")\n    # # Setup class names\n    with open(\"c",
        "suffix": "lass_names.txt\", \"r\") as filehandle:\n        class_names = [bread.strip() for bread in filehandle.readlines()]\n\n    # # Create model\n    model, model_",
        "output": "rch.cuda.is_available() else \"cpu\")\n    model.to(device)\n\n    # # Load model\n    # model.load_state_dict(torch.load(\"model.pth\"))\n\n    # # Load data\n    #",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 3.3252037442622604e-78,
        "chrf": 0.31478622656424077,
        "edit_distance": 96.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 43,
        "prefix": "    def predict(img: Image):\n        start = timer()\n\n        transformed_img = model_transforms(img).unsqueeze(0).to(devi",
        "middle": "ce)\n\n        model.to(device)\n        model.eval()\n\n        with torch.inference_mode():\n           ",
        "suffix": " pred_logit = model(transformed_img)\n            pred_prob = torch.softmax(input=pred_logit, dim=1)\n\n        pred_labels_and_probs = {\n            cla",
        "output": "ze)\n        transformed_img = transformed_img.to(device)\n        pred_logit = model(transformed_img)\n        pred_prob = torch.softmax(input=pred_logit, dim=1)\n\n        pred_",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 0.0,
        "chrf": 0.16615268954533277,
        "edit_distance": 103.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 44,
        "prefix": "    def predict(img: Image):\n       ",
        "middle": " start = timer()\n\n        transformed_img = model_transforms(img).unsqueeze(0).to(device",
        "suffix": ")\n\n        model.to(device)\n        model.eval()\n\n        with torch.inference_mode():\n            pred_logit = model(transformed_img)\n            pre",
        "output": "     transformed_img = transform(img)\n            transformed_img = torch.unsqueeze(transformed_img, 0)\n            transformed_img = transformed_img.to(device)\n            pred_logit = model(transformed_img",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 5.554837769749797e-155,
        "chrf": 0.32193795933458186,
        "edit_distance": 140.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    },
    {
        "example_id": 45,
        "prefix": "def create_effnetb2(num_of_classes: int, device=\"cuda\"):\n\n    model_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n    transforms = model_weights.transforms()\n    mode",
        "middle": "l = torchvision.models.efficientnet_b2(weights=model_weights).to(device) #",
        "suffix": " noqa 5501\n\n    for param in model.features.parameters():\n        param.requires_grad = False\n\n    set_seeds(42)\n\n    # # Set cllasifier to suit probl",
        "output": "l = transforms.Compose([transforms.Resize(224), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485, 0.456, 0.40",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 6.484592771860512e-155,
        "chrf": 0.06895463189826508,
        "edit_distance": 110.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 46,
        "prefix": "def create_effnetb2(num_of_classes: int, device=\"cuda\"):\n\n    model_weights = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n    transforms = model_weights.transforms()\n    model = torchvision.models.efficientnet_b2(weights=model_weights).to(device) # noqa 5501\n\n    for ",
        "middle": "param in model.features.parameters():\n        param.requires_grad = False\n",
        "suffix": "\n    set_seeds(42)\n\n    # # Set cllasifier to suit problem\n    model.classifier = nn.Sequential(\n        nn.Dropout(p=0.2, inplace=True),\n        nn.L",
        "output": "num_of_classes in range(num_of_classes):\n        model.classifier.add_module(\n            \"classifier{}\".format(num_of_classes),\n            model.classifier[num_of_classes].to(device),",
        "model": "starcoder",
        "rating": "incorrect",
        "bleu": 1.1640469867513693e-231,
        "chrf": 0.09139051257788354,
        "edit_distance": 145.0,
        "exact match": 0.0,
        "Manual Rating": 0.0
    },
    {
        "example_id": 47,
        "prefix": "def set_seeds(seed: int = 42):\n\n    # Se",
        "middle": "t the seed for general torch operations\n    torch.manual_seed(seed)\n    # Set the seed for CUDA torch operations (ones th",
        "suffix": "at happen on the GPU)\n    torch.cuda.manual_seed(seed)",
        "output": "ttings\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\n    # GPU settings\n    torch.cuda.manual_seed_all(seed)\n    torch.cuda.manual_seed(",
        "model": "starcoder",
        "rating": "partially_correct",
        "bleu": 3.690840039559348e-232,
        "chrf": 0.30343387031149344,
        "edit_distance": 103.0,
        "exact match": 0.0,
        "Manual Rating": 1.0
    }
]